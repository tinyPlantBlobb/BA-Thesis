{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import tarfile\n",
    "import whisper\n",
    "import torchaudio\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from transformers import SeamlessM4TModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO exchange for the proper data set setup\n",
    "\n",
    "languages = {\"af_za\": \"Afrikaans\", \"am_et\": \"Amharic\", \"ar_eg\": \"Arabic\", \"as_in\": \"Assamese\", \"az_az\": \"Azerbaijani\", \"be_by\": \"Belarusian\", \"bg_bg\": \"Bulgarian\", \"bn_in\": \"Bengali\", \"bs_ba\": \"Bosnian\", \"ca_es\": \"Catalan\", \"cmn_hans_cn\": \"Chinese\", \"cs_cz\": \"Czech\", \"cy_gb\": \"Welsh\", \"da_dk\": \"Danish\", \"de_de\": \"German\", \"el_gr\": \"Greek\", \"en_us\": \"English\", \"es_419\": \"Spanish\", \"et_ee\": \"Estonian\", \"fa_ir\": \"Persian\", \"fi_fi\": \"Finnish\", \"fil_ph\": \"Tagalog\", \"fr_fr\": \"French\", \"gl_es\": \"Galician\", \"gu_in\": \"Gujarati\", \"ha_ng\": \"Hausa\", \"he_il\": \"Hebrew\", \"hi_in\": \"Hindi\", \"hr_hr\": \"Croatian\", \"hu_hu\": \"Hungarian\", \"hy_am\": \"Armenian\", \"id_id\": \"Indonesian\", \"is_is\": \"Icelandic\", \"it_it\": \"Italian\", \"ja_jp\": \"Japanese\", \"jv_id\": \"Javanese\", \"ka_ge\": \"Georgian\", \"kk_kz\": \"Kazakh\", \"km_kh\": \"Khmer\", \"kn_in\": \"Kannada\", \"ko_kr\": \"Korean\", \"lb_lu\": \"Luxembourgish\", \"ln_cd\": \"Lingala\", \"lo_la\": \"Lao\", \"lt_lt\": \"Lithuanian\", \"lv_lv\": \"Latvian\", \"mi_nz\": \"Maori\", \"mk_mk\": \"Macedonian\", \"ml_in\": \"Malayalam\", \"mn_mn\": \"Mongolian\", \"mr_in\": \"Marathi\", \"ms_my\": \"Malay\", \"mt_mt\": \"Maltese\", \"my_mm\": \"Myanmar\", \"nb_no\": \"Norwegian\", \"ne_np\": \"Nepali\", \"nl_nl\": \"Dutch\", \"oc_fr\": \"Occitan\", \"pa_in\": \"Punjabi\", \"pl_pl\": \"Polish\", \"ps_af\": \"Pashto\", \"pt_br\": \"Portuguese\", \"ro_ro\": \"Romanian\", \"ru_ru\": \"Russian\", \"sd_in\": \"Sindhi\", \"sk_sk\": \"Slovak\", \"sl_si\": \"Slovenian\", \"sn_zw\": \"Shona\", \"so_so\": \"Somali\", \"sr_rs\": \"Serbian\", \"sv_se\": \"Swedish\", \"sw_ke\": \"Swahili\", \"ta_in\": \"Tamil\", \"te_in\": \"Telugu\", \"tg_tj\": \"Tajik\", \"th_th\": \"Thai\", \"tr_tr\": \"Turkish\", \"uk_ua\": \"Ukrainian\", \"ur_pk\": \"Urdu\", \"uz_uz\": \"Uzbek\", \"vi_vn\": \"Vietnamese\", \"yo_ng\": \"Yoruba\"}\n",
    "selection = widgets.Dropdown(\n",
    "    options=[(\"Select language\", None), (\"----------\", None)] + sorted([(f\"{v} ({k})\", k) for k, v in languages.items()]),\n",
    "    value=\"ko_kr\",\n",
    "    description='Language:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "selection\n",
    "\n",
    "lang = selection.value\n",
    "language = languages[lang]\n",
    "\n",
    "assert lang is not None, \"Please select a language\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialise the models used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper\n",
    "asr_model = whisper.load_model(\"medium\")\n",
    "options = dict(language=language, beam_size=5, best_of=5)\n",
    "transcribe_options = dict(task=\"transcribe\", **options)\n",
    "translate_options = dict(task=\"translate\", **options)\n",
    "\n",
    "# inhouse\n",
    "#inhouse_model #= torch.hub.load()\n",
    "\n",
    "# DeltaLM\n",
    "delta_path= \"https://deltalm.blob.core.windows.net/deltalm/deltalm-base.pt\"\n",
    "delta_model = torch.load(delta_path)\n",
    "#delta_model = torch.hub.load(\"pytorch/fairseq\", \"transformer_lm.wmt19.en\", tokenizer=\"moses\", bpe=\"fastbpe\")\n",
    "\n",
    "# SeamlessLM\n",
    "seamless_model = SeamlessM4TModel.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_path = download_asset(\"dataset/IWSLT23.tst2023.en-de.tar.gz\")\n",
    "tar_item = \"IWSLT23.tst2023.en-de/benchmark/en-de/tst2023/wav/ted_13587.wav\"\n",
    "with tarfile.open(tar_path, mode=\"r\") as tarfile_:\n",
    "    fileobj = tarfile_.extractfile(tar_item)\n",
    "    waveform, sample_rate = torchaudio.load(fileobj)\n",
    "\n",
    "\n",
    "#def download(url: str, target_path: str):\n",
    "#    with urllib.request.urlopen(url) as source, open(target_path, \"wb\") as output:\n",
    "#        with tqdm(total=int(source.info().get(\"Content-Length\")), ncols=80, unit='iB', unit_scale=True, unit_divisor=1024) as loop:\n",
    "#            while True:\n",
    "#                buffer = source.read(8192)\n",
    "#                if not buffer:\n",
    "#                    break\n",
    "\n",
    "#                output.write(buffer)\n",
    "#                loop.update(len(buffer))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = 'WMT21_DA_test'\n",
    "data_root_path = '../data'\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'de'\n",
    "\n",
    "references = []\n",
    "transcriptions = []\n",
    "translations = []\n",
    "\n",
    "for audio, text in tqdm(dataset):\n",
    "    transcription = asr_model.transcribe(audio, **transcribe_options)[\"text\"]\n",
    "    translation = asr_model.transcribe(audio, **translate_options)[\"text\"]\n",
    "    \n",
    "    transcriptions.append(transcription)\n",
    "    translations.append(translation)\n",
    "    references.append(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model with whisper medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_model = whisper.load_model(\"medium\")\n",
    "encoded = asr_model.encode(text, **options)\n",
    "logits = asr_model.decode(encoded, **options)[\"logits\"]\n",
    "\n",
    "\n",
    "options = dict(language=language, beam_size=5, best_of=5)\n",
    "transcribe_options = dict(task=\"transcribe\", **options)\n",
    "translate_options = dict(task=\"translate\", **options)\n",
    "references = []\n",
    "transcriptions = []\n",
    "translations = []\n",
    "outputptobabilities = []\n",
    "# Returns the last layer proabbliities of the model as a dict containing the decoded text and the segments and the language\n",
    "asr_model.eval()\n",
    "\n",
    "\n",
    "for audio, text in tqdm(dataset):\n",
    "    outputptobability = asr_model(audio)\n",
    "    transcription = asr_model.transcribe(audio, **transcribe_options)[\"text\"]\n",
    "    translation = asr_model.transcribe(audio, **translate_options)[\"text\"]\n",
    "\n",
    "    outputptobabilities.append(outputptobability)\n",
    "    transcriptions.append(transcription)\n",
    "    translations.append(translation)\n",
    "    references.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the glass box info (in this case weights from the cross attention layers) from the models I will need Hooks to the layers. they are registered like this and will be called every time after the forward functuon is called:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for the ASR part that are not hooks:\n",
    "he translation probabaility approach expanded to the ASR part so the sequence level transcription probability normalised by audio length\n",
    "The mean Transcription porbability of the system for the translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcriptionProbability(tensor, **options):\n",
    "    result = {\"translationProb\": torch.nn.functional.softmax(tensor, dim=-1),\"translationMean\":torch.mean(tensor, dim=-1).mean(dim=0)}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that are needed for the NMT part of the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardDeviation(probs):\n",
    "    return torch.sqrt(torch.mean(probs**2, dim=-1)-(torch.mean(probs, dim=-1) ** 2 ))\n",
    "\n",
    "def translationProbabilities(tensor, **options):\n",
    "    with torch.no_grad():\n",
    "        return torch.nn.functional.log_softmax(tensor, dim=-1)\n",
    "    \n",
    "def softmaxEntropy(outputSequence):\n",
    "    probs = torch.nn.functional.softmax(outputSequence, dim=-1)\n",
    "    return -np.divide(1,len(outputSequence))* torch.sum(torch.sum(probs * torch.log(probs), dim=-1), dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dropout based approach functions\n",
    "These need to calculate the Mean and Variance over the results of several forward passes with the set dropout to model the Uncertainty. the Dropout perturbes the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO FIX THE DROPOUT SINCE IT PROBABLY DOESN'T WORK LIKE THIS RN \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropoutTranslationProbability(probabilities, **options):\n",
    "    asr_model.config.dropout = 0.3\n",
    "    with torch.no_grad():\n",
    "        # as proposed by the paper\n",
    "        # 30 interference passes for the posteriour probabily but 10 should also be fine\n",
    "        probability= []\n",
    "        for _ in range(30):\n",
    "            probability.append(asr_model(probabilities))\n",
    "        prob = torch.divide(torch.mean(probability,dim = -1), 30)\n",
    "        var = torch.nn.var(probability, 30)\n",
    "        return {\"dropoutprobabilty\":prob, \"variance\": var, \"D-combo\": (1-np.divide(prob,var))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dict(reference=references, transcription=transcriptions, translation=translations, probability=outputptobabilities))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooks if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QKs = [None] * model.dims.n_text_layer\n",
    "\n",
    "#for i, block in enumerate(model.decoder.blocks):\n",
    " #   block.cross_attn.register_forward_hook(\n",
    "  #      lambda _, ins, outs, index=i: QKs.__setitem__(index, outs[-1])\n",
    "   # )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
