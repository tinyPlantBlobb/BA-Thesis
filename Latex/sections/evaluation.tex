%% Karlsruhe Institute of Technology
%% Institute for Anthropomatics and Robotics (IAR)
%% Artificial Intelligence for Language Technologies (AI4LT) lab
%%
%% Prof. Dr. Jan Niehues
%% Lab's website https://ai4lt.anthropomatik.kit.edu/english/index.php

\chapter{Evaluation}
\label{ch:Evaluation}
The evaluation of results of the experiments that were conducted on the benchmark section of the IWSLT 2023 dataset \cite{sperber2024evaluating} with regards to \autoref{ch:Dataset} as the relevant changes and preprocessing that was done.

The resulting scores are then pearson correlated \cite{2020SciPy-NMeth} to comet\footnote{the used comet implementation can be found here: https://github.com/Unbabel/COMET} scores as well as word error rates and compare those. The used pearson correlation implementation is the huggingface implementation \cite{huggingfacepearsonr}.

The comet scores are retrieved by using the regular translation from the MT models as well as the reference source transcription and the reference translation. 
These scores are used across all evaluation metrics in the MT category. 
%% -------------------
%% | Example content |
%% -------------------

\section{Transcription evaluation}
To evaluate how good the transcription quality estimation is, the Word error rate\footnote{the used WER implementation can be found here: https://github.com/analyticsinmotion/werpy} (see \autoref{wer}) is used as reference score to compare the transcription quality estimation metric by correlating the WER scores with the help of the pearson correlation \cite{2020SciPy-NMeth}.
As WER is case sensitive, both the model result and the reference are normalised to be all lowercase, with single spaces, no leading or trailing blank spaces, and no punctuation.

The resulting transcription probabilities plotted over the according WER values are shown in \autoref{fig:transcript scatter plot} and the pearson correlation can be found in \autoref{transcription results}. 
The plots in \autoref{fig:transcript scatter plot} demonstrate quite nicely the impact of normalizing the scores with the sequence length. \autoref{fig:transcript scatter plot base} shows less of a trend with the high model scores and low WER scores than \autoref{fig:transcript mean scatter plot}, which shows a more focused trend of higher WER scores and lower probability mean scores. 
However both methods show outlier values. For the transcription mean these are mostly low probability scores that have a low WER score as well, which means they are good transcripts. 
This also overlaps with the pearson correlation score, where the correlation score for the transcription mean is rounded 0.605, whereas the non mean correlation score for the transcription probability is 0.331. 

\begin{figure}[ht]
    \centering%
    \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/transcriptbasescore.png}
        \caption{transcript scores over WER reference score}
        \label{fig:transcript scatter plot base}
    \end{subfigure}
    \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/transcriptmeanbasescore.png}
        \caption{transcript mean over WER reference score}
        \label{fig:transcript mean scatter plot}
    \end{subfigure}
    \caption{plot over the transcription probabilities, the transcription means, and the WER scores}
    \label{fig:transcript scatter plot}
\end{figure}

This shows that taking the mean transcription probability is a good metric for estimating the transcription quality, as there are only a few outliers, and a transcription probability mean score close to 0 means it is highly likely that the WER score will also be low. 

\begin{table}[ht]
\centering%
  \begin{tabular}{l|d{2.6}}
  & \multicolumn{1}{l}{Whisper} \\ \hline
  Transcription Probability (-)& -0.33164 \\
  Transcription mean (-)& -0.60496 \\ \hline
  Dropout transcription (-)& -0.2760 \\
  Dropout mean (-)& -0.3672 \\
  Dropout variance (+)&  +0.1233\\
  Dropout mean variance (+)& -0.0873\\
  Dropout combo (+)& -0.1624\\
  Dropout mean combo (+)& +0.2684\\
  \end{tabular}

  \caption{result from the transcription part of the cascaded model, correlated with WER scores, with the reference and model transcript normalized, the sign on the left denotes what sign a row should have}
    \label{transcription results}
\end{table}

\section{Translation evaluation}
For the evaluation of the translation scores, the reference score is generated with the help of comet \cite{rei-etal-2020-comet}. This way of generating the reference score means that a score close to 1 is a good translation and a score close to 0 is a bad translation that is no better than random chance.
\begin{table}[ht]
\centering%
\begin{tabular}{l|d{2.6}d{2.6}d{2.6}}
&\multicolumn{1}{l}{Seamless}& \multicolumn{1}{l}{DeltaLM}&\multicolumn{1}{l}{Seamless e2e}\\ \hline
Translation & 0.37592 & 0.28284 & 0.656299\\ 
Softmax Entropy (-)& 0.30604&0.18071 & 0.60334 \\
Standard deviation (-)& 0.32905  & 0.25363& 0.67148 \\ \hline
Dropout translation & 0.150755& 0.282556& 0.14194\\
Dropout Variance (-)&-0.106986 & -0.16285& 0.13080\\
Dropout combo (-)& -0.163593& 0.179621& -0.20624\\ \hline
unified score$_{prod}$ (-)& 0.32965 & 0.05348 &\\
unified score mean$_{prod}$(-)& -0.50055& 0.12587& \\
unified score$_{add}$&0.31837& 0.06600&\\
unified score mean$_{add}$&0.56032&0.168710&\\
\end{tabular}
\caption{Correlation scores for the separate models and calculated quality scores. The sign on the left denotes whether the expected correlation value is supposed to positive or negative. If no signs are added to the values in a row, then all of the values have the expected sign.}
\label{results}
\end{table}

Those reference scores are then also pearson correlated with the scores from the model. The correlated scores for the translation part of the cascaded model and the speech translation part of the end-to-end model are found in \autoref{results}. 

As can be seen in \autoref{results} the scores retrieved from the model correlate well on the cascaded models, with correlation scores of 0.376 for seamless and 0.283 for DeltaLM, and really well on the end to end model with a correlation score of 0.656. 

The drop on the DeltaLM model scores could be because of model differences with the seamless text-to-text translation model or due to the different score retrieval method; for this, more experiments would have to be run with different models and the different toolkits. 
The drop could also be because even if the seamless model used for text-to-text translation only uses text-to-text translation, it might have learned different things during training that might help with translating. However, this can be put down to model differences in the end. 

Another reason why the DeltaLM score on the translation probability is lower could be because it has more outliers with smaller translation probabilities but reference scores that are greater than 0.5, which can be seen in \autoref{fig:translationeval scatter plot translation}. However what can also be seen from the scatter plots is that DeltaLM has fewer low reference scores than seamless has. 
The end-to-end scores are that much higher, with 0.665 to 0.377 or 0.283, since there are no potential errors from the transcription part, but it could also be that the model simply translates a lot better when using seamless for spoken language translation. 

\begin{figure}[ht]
    \centering%
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessgenprob.png}
        \caption{spread of the translation probability scores on seamless over the reference scores}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/dlmgenprob.png}
        \caption{spread of the translation probability scores on DeltaLM over the reference scores}
    \end{subfigure}
   \caption{Model translation scores over the corresponding comet scores. The left side shows the seamless scores, the right side shows the DeltaLM scores.}
    \label{fig:translationeval scatter plot translation}
    \end{figure}

The entropy scores anti-correlate with the reference scores. This is logical since the higher the entropy is, the worse the translation. 
When looking at the absolute value of the correlation, so ignoring the sign, it can be seen that they correlate less with the references than the translation scores, as there is a 0.07 difference on seamless for text and 0.053 difference for end-to-end translation, as well as a 0.1 difference on DeltaLM. They still correlate well with it, with correlation scores of 0.305 for t2t seamless, 0.180 for DeltaLM, and 0.603 for e2e seamless.

The sofmax entropy scores plotted over the reference comet scores are shown in \autoref{fig:translationeval scatter plot entropy}, which also show quite well why the seamless pearson correlation scores are so much higher than the DeltaLM correlation scores. This again might be because of the score retrieval method or it might be due to model differences. 
The end-to-end translation softmax entropy scores are once again higher than the text-to-text translation models. This is most likely again due to fewer possible errors from the transcription step.
\begin{figure}[ht]
        \centering%
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessentropy.png}
        \caption{seamless entropy scores over comet scores}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/dlmentropy.png}
        \caption{DeltaLM entropy scores over comet scores}
    \end{subfigure}
    \caption{Model softmax entropy scores over the corresponding comet scores. The left side shows the seamless scores, the right side shows the DeltaLM scores}
    \label{fig:translationeval scatter plot entropy}
\end{figure}

The standard deviation scores anti-correlate, just like the entropy scores. This is also due to how the standard deviation works, as a lower standard deviation means less spread in the probabilities from the mean of those probabilities. 
Similarly to the softmax entropy, the absolute standard deviation correlation scores are also smaller than the translation scores, but they correlate more to the reference scores than the entropy scores, with correlations scores of 0.329 for t2t seamless, 0.254 for DeltaLM and 0.671.

Curiously enough the seamless end-to-end scores for the standard deviation have a higher correlation score than the translation score correlation with a correlation score of 0.671, which is most likely from the end-to-end nature of the model. This means the model does not have to use an intermediate transcript and thus generating each top token can have different behaviour than the text to text models. It could also stem from the multilingual part of seamless. 

The standard deviation scores are plotted over the comet scores in \autoref{fig:translationeval scatter plot stddiv} which also shows well how the scores are anti-correlated. It also shows that the scores are very similar to how the regular translation probability scores look when plotted. 
    \begin{figure}
            \centering%
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessstddiv.png}
        \caption{seamless standard deviation scores over comet scores}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/dlmstddiv.png}
        \caption{deltaLM standard deviation scores over comet scores}
    \end{subfigure}
    \caption{Model standard deviation scores over the corresponding comet scores. The left side shows the seamless scores, the right side shows the deltaLM scores}
    \label{fig:translationeval scatter plot stddiv}
\end{figure}

Based off of these results and possible error causes, it can be gathered that the best metric for quality estimation in text and spoken language translation is the translation probability.
This is both because it is easy to implement in most models and frameworks or toolkits, where most of the time it is already included, and because it delivers good correlation results with reference scores, as explained above.

The next best metric would be the standard deviation of the decoding step probabilities. This is the case because it delivers good results in terms of correlation, which might also have more potential for new scores on end-to-end models. It is also fairly easy to implement the standard deviation, since getting the probability of the top token is what some toolkits or frameworks already allow. Compiling the different scores during translation is also not difficult, and applying the standard deviation to these scores, which is part of any maths library, is also simple. 

The worst method of these 3 methods would be the softmax entropy. This is because if the toolkit does not have it implemented already or a way to get the probability distribution over the vocabulary at each decoding step, it can be difficult to implement, and it does not deliver scores that are better than any of the other scores proposed in this section. However the softmax entropy might be an interesting metric if used during dropout on text-to-text translation; more on that can be found in \autoref{dropout softmax entropy}.

\section{Dropout evaluation}
The dropout score is calculated by taking the mean of the dropout probabilities of the model, the variance of the dropout probabilities, and a combination of both. The dropout score is then Pearson correlated with the comet scores or the word error scores in the case of the transcription. 
The reference scores are computed with the non dropout transcriptions and translations, since the dropped out sequences can differ a lot from the non-dropout sequences, which would impact the reference score and not accurately represent the reference. 
The correlation results are listed in \autoref{results} for the translation part and \autoref{transcription results} for the transcription dropout. 

\autoref{fig:dropout transcript scores} shows the differences between the transcription probabilities and transcription mean in dropout. 
As can be seen, if the scores are not normalized there is a lot less clear correlation between the low word error scores and high scores, as there are a lot more scores that have a low WER score but a broad spectrum of probability scores. This reflects in the correlation scores; the scores gathered with the mean of the transcription have a correlation score of 0.367 where the not normalised scores only have a correlation of 0.276. 
\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropouttranscript.png}
        \caption{dropout transcription probability scores over the reference scores}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropouttranscriptmean.png}
        \caption{dropout transcription mean scores over the reference scores}
    \end{subfigure}
    \caption{transcription dropout scores plotted over the WER; left is the base scores, right is the mean scores}
    \label{fig:dropout transcript scores}
    \end{figure}
    
The variance correlation is a lot higher in the non mean dropout with a correlation score of 0.123 than it is for the mean probability dropout with a score of 0.087. This is due to a lot more variance in the length of the resulting transcripts and the impact of this variation in length on the score. The variance of the mean scores in dropout is a lot smaller; this is most likely due to the normalisation and a resulting smaller impact on the scores. It should also be noted that the transcription mean variance correlation score is quite close to 0 and because of this not really statistically significant. A plot of these values can be found in \autoref{fig:dropout transcript variance scores}, which also shows how not correlated the transcription mean dropout variance scores are to the WER. 
    \begin{figure}
        \centering%
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropouttranscriptvar.png}
        \caption{spread of the dropout transcription variance scores over the reference scores}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropouttranscriptmeanvar.png}
        \caption{spread of the dropout transcription mean variance scores over the reference scores}
    \end{subfigure}
    \caption{transcription dropout variance scores plotted over the wer, left is the base scores, right half is the mean scores}
    \label{fig:dropout transcript variance scores}
    \end{figure}
    
The combination score, which consists of the dropout transcription score and the dropout variance score, once again show decent correlation with the WER scores. There are correlation scores of 0.162 for the non normalized scores and 0.268 for the normalised scores. These are lower than the dropout transcription score correlation by about 0.1 for each, but with how much lower the variance correlations are this is to be expected.

The sign difference in the correlation scores comes most likely from the sign difference in the variance and the formula of how the combination score is calculated at each step, as well as the fact that the non normalized transcription variance scores are significantly higher than the variance values of the mean which leads to smaller values in the score. 

The plotted combo scores both for the transcription dropout scores and transcription mean dropout scores can found in \autoref{fig:dropout transcript combo scores}. They once again show that the mean displays a bit better distinction around the WER score of 0 than the transcription score. 
\begin{figure}
        \centering%
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropouttranscriptcombo.png}
        \caption{spread of the dropout transcription combination scores over the reference scores}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropouttranscriptmeancombo.png}
        \caption{spread of the dropout transcription mean combination scores over the reference scores}
    \end{subfigure}
    \caption{transcription dropout scores plotted over the wer, left is the base scores, right half is the mean scores}
    \label{fig:dropout transcript combo scores}
\end{figure}

The baseline for the dropout is the dropout translation, found under that name in Table \autoref{results}. As can be seen the correlation between the seamless results, both the translation only with a score of 0.151 and the end to end versions with a correlation score of 0.142, is lower than the ones from DeltaLM, which has a correlation score of 0.282.  

This is most likely due to how the dropout is implemented or used with the different toolsets/frameworks, but it could also be due to model differences. To properly distinguish between those possibilities more experiments would be needed where dropout is enabled only on different parts of the model, so for example just the decoder, just the encoder, including attention and the like. Alternatively it might also stem from different versions of the input into the dropout part of seamless, but that would not explain the drastically lower score on the end to end version of seamless, since that takes the audio as an input. 
A plot of these scores can be seen in \autoref{fig:dropout translation probability scores}.
\begin{figure}[ht]
    \centering%
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropprob.png}
        \caption{spread of the dropout translation probability scores over the reference scores for seamless}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/dlmdropprob.png}
        \caption{spread of the dropout translation probability scores over the reference scores for deltalm}
    \end{subfigure}
        \caption{dropout probability scores plotted over the comet scores, left is the seamless scores, right half is the deltaLM scores}
        \label{fig:dropout translation probability scores}
    \end{figure}

The variance scores are all smaller than the dropout probability scores, which as seen in the transcription part is to be expected. While the pearson correlation of the translation dropout variance scores are smaller than the pearson correlation of the dropout translation probability score, they are not that much smaller than them. The pearson correlation score can be found in \autoref{results} and a plot of the dropout variance scores over the reference scores can be seen in \autoref{fig:dropout translation variance score}.

The variance score is once again anti-correlated to the comet score, this is because of of how the variance works where a smaller score denotes a better result. 
The end-to-end dropout variance is not anti correlated, which can very well be due to a difference in reference score or can be a result of dropout.
As using dropout with the end-to-end model sometimes produces long stings of nonsense and because of how seamless is trained and what it can translate, those long strings do not always stick to a single language but rather switch through different ones and occasionally include characters from different alphabets. 
%An example of this can be found in \autoref{seamlesse2enonesense}
\begin{figure}[ht]
        \centering%
        \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropoutvariance.png}
        \caption{spread of the dropout translation probability variance scores over the reference scores for seamless}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/dlmdropoutvariance.png}
        \caption{spread of the dropout translation probability variance scores over the reference scores for deltalm}
    \end{subfigure}
        \caption{dropout variance scores plotted over the comet scores, left is the seamless scores, right half is the deltaLM scores}
        \label{fig:dropout translation variance score}
\end{figure}
    
The combination score made up out of the the other dropout scores show a stronger correlation with the reference scores than the variance but less than the translation probability for the cascaded models, with scores of -0.163 for seamless t2t and 0.180 for DeltaLM, which considering how it is defines is to be expected. 
The flipped sign on the correlation score for DeltaLM is most likely due to the incredibly small dropout variance scores and since the dropout translation score, which is negative, is divided by this variance score and then subtracted from 1.
However it is stronger correlated in the case of the end to end model with a correlation score of -0.206, this is most likely due to the correlation instead of anti correlation in the variance and the very similar correlation score between the dropout translation and dropout variance scores. 
The an overview over the pearson correlation scores again can be found in \autoref{results} and a plot of the scores for seamless t2t and DeltaLM over the reference scores can be found in \autoref{fig:dropout translation combo}. 

\begin{figure}[ht]
        \centering%
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/seamlessdropoutcombo.png}
        \caption{spread of the dropout translation probability combo scores over the reference scores}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\textwidth]{Latex/sections/images/dlmdropoutcombo.png}
        \caption{spread of the dropout translation probability combo scores over the reference scores}
    \end{subfigure}
    \caption{dropout combo scores plotted over the comet scores, left is the seamless scores, right half is the deltaLM scores}
    \label{fig:dropout translation combo}
\end{figure}

\section{One unified score}
Since several different metrics are used in the translation part of the cascaded model it is interesting which one might be the best choice to use in a unified score. from the text translation paper \cite{fomicheva2020unsupervised} we can gather that different metrics work better for different language groups, as this thesis only tested on english to german translation no definite choice can be made without looking at other languages as well.

For a unified score the baselines, which are the translation and transcription probability, are multiplied. 
The resulting pearson score that can be found in \autoref{results} is calculated by correlating this unified score, product of translation probability and transcription probability, with the the comet score multiplied by the by the WER mapped to be from 0 to 1 by dividing all WER scores by the worst, so highest, WER score in the dataset, if finding the highest WER score for the dataset is not possible using 100 as a value is a decent option, as most WER scores are below that, and subtracting it from 1. 
This is can be described mathematically as 
$$reference = cometscore*(1-\frac{WER}{max(WER)})$$
which was chosen since the transcription probability is anti-correlated to the WER and since the best score of the WER is 0 that had to be taken into account as it ruled out just flat out dividing the comet score by the WER.


\begin{table}[ht]
    \centering
    \begin{tabular}{l|d{2.6}d{2.6}|d{2.6}d{2.6}}
    &\multicolumn{1}{l}{Seamless+base}& \multicolumn{1}{l}{DeltaLM+Whisper}& \multicolumn{1}{l}{Seamless+mean}&\multicolumn{1}{l}{DeltaLM+mean}\\\hline
translation (-)& -0.32965 & -0.05348 & -0.50055& 0.12587 \\
softmax entropy (-)& 0.3703422  & -0.132959  &0.558637 &-0.129452 \\
standard deviation&0.2670221  & 0.158974  &0.4710036  &0.1405853 \\\hline
dropout probability &-0.368084&  -0.1526369 &-0.465468  &-0.227128 \\
dropout variance& -0.134160&  -0.048070&  0.021499 & -0.159075\\
 combo &0.01635226&  0.1689276&  -0.296981 & 0.138246 \\
    \end{tabular}
    \caption{pearson correlations of multiplicative scores for various other metrics. The columns are separated by weather the transcript probability, denoted with base, or the transcription mean was used to calculate the score as well as which translation model.}
    \label{tab:multi uni scores}
\end{table}

The correlation scores for the multiplication version of the unified scores are shown shown in \autoref{tab:multi uni scores}. The translation probability based score, which can be seen as a baseline for the other correlation scores, has a correlation of 0.329 for the non normalized transcription scores and a score of 0.501 with the normalized scores on seamless, where as the unified scores calculated with the translation probability scores from DeltaLM have a much lower correlation score with the reference score of only 0.053 with non normalized transcription scores and a correlation of 0.126 if the normalized transcription scores are used. 

The softmax entropy based score has the highest correlation of 0.559 on seamless for the mean score and a correlation score of 0.37 for the transcription probability, where as the DeltaLM correlation scores are 0.133 for the non normalized score and 0.13 for the transcription mean score. The difference in correlation between the models is most likely due to the difference in correlation scores of the softmax entropy scores in the first place. The higher correlation than the baseline with the translation scores is most likely because of how the reference score is calculated but it could also be a difference in the entropy scores that the different models produce.

The standard deviation correlation scores are lower than the translation correlation for seamless with correlation scores of 0.267 and 0.471, in the case of DeltaLM the correlation scores are higher like the score that was calculated with the transcription probability going up by 0.1 in correlation and the transcription mean unified score going up by 0.02. These highest scores are most likely due to the anti-correlation property of the standard deviation score in the MT part of the model. 

The dropout based scores show a very similar behaviour as the dropout of the different components where the dropout probability has a correlation score that is similar to the non dropout correlation score, in this case scores of 0.36 and 0.46 for seamless and 0.15 and 0.23 for DeltaLM. 
The Variance scores are worse or significantly worse scores. The really interesting thing is the fact that it changes which transcription score gives a bad correlation score in combination with the translation model. The scores retrieved from seamless and multiplied with the transcription mean are significantly worse, with a correlation of 0.021, at predicting the reference score than if it was multiplies with the non normalised transcription probability, which has a correlation of 0.13, where as on DeltaLM this is the other way around and the  non mean score only has a correlation of 0.04 where as with the variance of the mean transcription it has a correlation of 0.15. Because of how the Combination score is calculated this also reflects in the correlations of those scores where the bad correlation scores on the variance create better correlation scores in the combo score and the other way around for the good correlation scores.

This once again shows that the seamless scores are on average about 2 times more correlated than the DeltaLM scores. It also shows that using the transcription mean in scores like this gives better results all around and that using the dropout probability, the translation probability and the standard deviation of the token probability to estimate the quality are all good metrics that can be calculated in a reasonable time frame. 


\begin{table}[ht]
    \centering
    \begin{tabular}{l|d{2.6}d{2.6}|d{2.6}d{2.6}}
&\multicolumn{1}{l}{Seamless+base}& \multicolumn{1}{l}{DeltaLM+base}&\multicolumn{1}{l}{Seamless+mean}& \multicolumn{1}{l}{DeltaLM+mean}\\ \hline
translation &0.31837& 0.06600&0.56032&0.168710\\
softmax entropy &0.171143 &0.099865 &0.1048499 &0.205844 \\ 
 standard deviation& 0.284749 &-0.010293 & 0.497750 &-0.057896 \\ \hline 
 dropout probability& 0.405961 &0.042960 &0.234955 &0.107331 \\ 
 dropout variance& -0.242118 &  -0.028931 &0.325615& 0.019440\\
 combo & -0.090351 & 0.189254 &-0.090917& 0.188630\\
    \end{tabular}
    \caption{pearson correlation scores that are added together from the different scores in the translation transcription categories. The columns are separated by weather the transcript probability, denoted with base, or the transcription mean was used to calculate the score as well as which translation model.}
    \label{tab:add uni scores}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{l|d{2.6}d{2.6}|d{2.6}d{2.6}}
&\multicolumn{1}{l}{Seamless+base}& \multicolumn{1}{l}{DeltaLM+base}&\multicolumn{1}{l}{Seamless+mean}& \multicolumn{1}{l}{DeltaLM+mean}\\ \hline
softmax entropy& -0.377987 &-0.099865  &-0.513472& -0.205843\\
 standard deviation &-0.306851 &-0.058635 &-0.545197& -0.148497\\\hline
 dropout probability& -0.405961 &-0.042960  &-0.234955 &-0.107331\\
 dropout variance &-0.242118 &-0.0289317 &0.325615 &  0.019441\\
 combo  &-0.090351 & 0.189254 &-0.090917& 0.188630\\ 
    \end{tabular}
    \caption{correlation scores of addition unified scores where the absolute of input scores has been taken}
    \label{tab:add abs uni score }
\end{table}

The correlation scores for the added together scores are shown in \autoref{tab:add uni scores}.
For the added together unified scores a very similar correlation scores are achieved when using the translation probability, however with the main difference that it is correlated instead of anti correlated for all of them. Seamless also again has the higher correlation scores with 0.328 for the not normalized transcription unified score and a correlation of 0.560 for the score that uses the length normalized  transcription score. Whereas DeltaLM has a correlation score of 0.066 for the non normalized score and a score of 0.169 for the normalized one, which is 0.04 higher than the multiplied score. A plot of these scores can be seen in \autoref{fig:uniscore add plot}. This difference in scores could very well be because of a difference in the original scores or sign differences in the scores. 

If the raw softmax entropy is used in the calculation of the unified score the scores look quite different, for seamless the non normalized transcription version of the score has a higher correlation than if the mean was used where as for seamless the opposite is the case. However the fact that the correlation scores are quite similar between the translation and softmax based scores might indicate that this might be due to a difference in the model scores, the signs of the scores. If the absolute of the scores is taken then the correlation scores are 0.378 with no transcript score normalization, 0.513 with transcript score normalisation on seamless and the same for DeltaLM. 

For the standard deviation based scores the correlation scores follow the same trend of the seamless scores being higher than the DeltaLM scores, adding together the raw scores gives correlation scores of 0.28 and 0.49 for seamless and on DeltaLM the scores are 0.01 and 0.05, however taking a look at the correlation of the absolute input scores this again gives better correlation results or 0.059 with transcription probability and 0.148 with the transcription mean. This is the case because the separate scores have different signs and the scores are in the same size range absolutely seen, especially the transcription mean. The seamless correlation scores also increase when taking the absolute to 0.306 and 0.545 respectively. 

 The dropout based scores show essentially the same effects as when multiplied where the seamless scores are a lot higher in correlation but in this case the non normalized dropout probability score is higher correlated than the mean dropout probability score, with correlation scores of 0.4 and 0.23 respectively. The correlation scores for DeltaLM are 0.04 on the non normalized scores and 0.107 on the normalized scores, which is most likely due to the same effects as on the translation probability version of the score, where they are simply not a good estimation and as has been seen before the dropout correlation is usually lower than the baseline anyway. The scores are also the same weather the raw scores are taken or the absolute. The dropout variance correlation score show a similar behaviour but for seamless the mean score once again has the higher correlation where as for DeltaLM the non normalized scores have a higher correlation. However it should be noted that the dropout variance scores for DeltaLM are very low with 0.029 and 0.019. 

 The correlation of dropout combination score shows that if both of the previous scores are well correlated the resulting scores is not correlated well and vice versa, this means that the seamless based scores are close to 0, with scores of 0.09 in both versions, where as the DeltaLM based scores have a correlation scores of 0.189 each. 

This shows that simply adding the scores gathered together is a possible way to get a unified score however due to different signs in scores, the absolutes should be used instead of the raw scores. And similarly to the version above the translation and standard deviation based scores are among the best correlated and seem to be the most reliable when used with the transcription mean. 
\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\linewidth]{Latex/sections/images/seamlesstranscripttranslation.png}
        \caption{seamless unified scores with non normalized transcription scores}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\linewidth]{Latex/sections/images/dlmtranscripttranslation.png}
        \caption{DeltaLM unified score with non normalized transcription scores}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\linewidth]{Latex/sections/images/seamlesstranscripttranslationmean.png}
        \caption{seamless unified scores with normalized transcription scores}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[width=\linewidth]{Latex/sections/images/dlmtranscripttranslationmean.png}
        \caption{deltalm unified scores with normalized transcription scores}
    \end{subfigure}
    \caption{Plot of the unified scored calculated by adding the translation and transcription scores together, a) and b) are calculated with the non normalized transcription scores, c) and d) with the normalized transcription scores}
    \label{fig:uniscore add plot}
\end{figure}

As for the linear interpolated a unified score made up of the translation and transcription probabilities differently, which is given in the formula $$unifiedscore_\alpha= \alpha TP_{transcript} + (1-\alpha)TP_{translation}.$$ 
As can be seen in \autoref{fig:uniscore correlation} changing the weight between the transcription and the translation scores has a noticeable impact on the correlation scores. 
This also shows that the weighing for cascaded models is at least partially model dependent, if not framework dependent, but using a high $\alpha$ seems to yield good results on the non-normalised unified scores in either case. 
For the normalised unified score the correlations seem to differ on what the best $\alpha$ value would be, for seamless it would be in the 0.3 to 0.4 range where as for DeltaLM it is around 0.98. 

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\linewidth]{Latex/sections/images/seamlessuniscoredistribution.png}
        \caption{seamless unified scores}
    \end{subfigure}
    \begin{subfigure}{0.4\linewidth}
        \includegraphics[width=\linewidth]{Latex/sections/images/dlmuniscoredistribution.png}
        \caption{deltaLM unified scores}
    \end{subfigure}
    
    \caption{Changes in correlation with different alpha values, the red line is for the unified score taken with the transcription mean, the blue line is the unified score gathered with the the non-normalised transcription score. }
    \label{fig:uniscore correlation}
\end{figure}

This shows that using the translation and length normalized transcription probabilities from cascaded models is a viable quality estimation, no matter if the translation and transcription scores are added together, multiplied or linearly interpolated for the score calculation. It also shows that finding the right weights for the transcription and translation parts can improve the correlation even more than simply adding or multiplying them together but to find out the right weights testing would have to be done as it seems to differ on a model basis.

But when compared to the end-to-end model these scores compare really well in terms of correlation, especially the added together cores where the transcription mean has been used. 



