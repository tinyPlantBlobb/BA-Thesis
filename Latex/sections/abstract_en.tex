%% Karlsruhe Institute of Technology
%% Institute for Anthropomatics and Robotics (IAR)
%% Artificial Intelligence for Language Technologies (AI4LT) lab
%%
%% Prof. Dr. Jan Niehues
%% Lab's website https://ai4lt.anthropomatik.kit.edu/english/index.php

\Abstract
This thesis explores unsupervised quality estimation for spoken language translation (SLT), leveraging glass-box features from neural models. With the increasing reliance on machine translation and automatic speech recognition (ASR) technologies, accurate quality assessment has become crucial to minimize human post-editing efforts. The study adapts established unsupervised metrics from text-based machine translation to evaluate SLT systems, focusing on cascaded and end-to-end models. Methods such as transcription probability, softmax entropy, and dropout uncertainty are employed to estimate the quality of transcription and translation. Additionally, a unified scoring approach is proposed to evaluate the overall performance of cascaded SLT systems. Experiments are conducted using state-of-the-art models like Whisper, SeamlessM4T, and DeltaLM, demonstrating the efficacy of the proposed metrics in correlating with standard evaluation measures. This work provides a framework for efficient quality estimation, facilitating improvements in SLT systems without reliance on extensive labeled data.