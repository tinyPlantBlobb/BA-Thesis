%% Karlsruhe Institute of Technology
%% Institute for Anthropomatics and Robotics (IAR)
%% Artificial Intelligence for Language Technologies (AI4LT) lab
%%
%% Prof. Dr. Jan Niehues
%% Lab's website https://ai4lt.anthropomatik.kit.edu/english/index.php

\Abstract
This thesis explores unsupervised quality estimation for spoken language translation (SLT), leveraging glass-box features from neural models. Estimation of the quality is crucial for knowing when a translation or transcription is of a bad quality and has to be human edited. This is especially important on machine translation and automatic speech recognition (ASR) technologies used in a cascaded SLT model. 

The thesis adapts established unsupervised metrics from text-based machine translation to evaluate SLT systems, focusing on cascaded models but also having a look at an end-to-end model.
Methods such as transcription probability, softmax entropy, standard deviation of token probabilities, and uncertainty quantification with dropout are employed to estimate the quality of transcription and translation. Additionally, different unified scoring approaches are proposed to evaluate the overall performance of cascaded SLT systems. Experiments are conducted using state-of-the-art models like Whisper, SeamlessM4T, and DeltaLM, demonstrating the efficacy of the proposed metrics in correlating with evaluation measures. 

We conclude that the transcription mean, the translation probability and standard deviation of token probabilities are good metrics to estimate the quality of Spoken Language translation ins cascaded model and translation probability and standard deviation are good metrics for end-to-end models. 
%This work provides a framework for efficient quality estimation, facilitating improvements in SLT systems without reliance on extensive labeled data.