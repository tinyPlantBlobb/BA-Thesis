@misc{fomicheva2020unsupervised,
      title={Unsupervised Quality Estimation for Neural Machine Translation}, 
      author={Marina Fomicheva and Shuo Sun and Lisa Yankovskaya and Frédéric Blain and Francisco Guzmán and Mark Fishel and Nikolaos Aletras and Vishrav Chaudhary and Lucia Specia},
      year={2020},
      eprint={2005.10608},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{Freitag_2017,
   title={Beam Search Strategies for Neural Machine Translation},
   url={http://dx.doi.org/10.18653/v1/W17-3207},
   DOI={10.18653/v1/w17-3207},
   booktitle={Proceedings of the First Workshop on Neural Machine Translation},
   publisher={Association for Computational Linguistics},
   author={Freitag, Markus and Al-Onaizan, Yaser},
   year={2017} }

@inproceedings{negri-etal-2014-quality,
    title = "Quality Estimation for Automatic Speech Recognition",
    author = "Negri, Matteo  and
      Turchi, Marco  and
      C. de Souza, Jos{\'e} G.  and
      Falavigna, Daniele",
    editor = "Tsujii, Junichi  and
      Hajic, Jan",
    booktitle = "Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",
    month = aug,
    year = "2014",
    address = "Dublin, Ireland",
    publisher = "Dublin City University and Association for Computational Linguistics",
    url = "https://aclanthology.org/C14-1171",
    pages = "1813--1823",
}
@inproceedings{BLEUMetric,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: a method for automatic evaluation of machine translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073083.1073135},
doi = {10.3115/1073083.1073135},
abstract = {Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}
@inproceedings{rei-etal-2020-comet,
    title = "{COMET}: A Neural Framework for {MT} Evaluation",
    author = "Rei, Ricardo  and
      Stewart, Craig  and
      Farinha, Ana C  and
      Lavie, Alon",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.213",
    doi = "10.18653/v1/2020.emnlp-main.213",
    pages = "2685--2702",
    abstract = "We present COMET, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-the-art levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metric. Our models achieve new state-of-the-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems.",
}

@inproceedings{blain-etal-2020-quality,
    title = "Quality In, Quality Out: Learning from Actual Mistakes",
    author = "Blain, Frederic  and
      Aletras, Nikolaos  and
      Specia, Lucia",
    editor = "Martins, Andr{\'e}  and
      Moniz, Helena  and
      Fumega, Sara  and
      Martins, Bruno  and
      Batista, Fernando  and
      Coheur, Luisa  and
      Parra, Carla  and
      Trancoso, Isabel  and
      Turchi, Marco  and
      Bisazza, Arianna  and
      Moorkens, Joss  and
      Guerberof, Ana  and
      Nurminen, Mary  and
      Marg, Lena  and
      Forcada, Mikel L.",
    booktitle = "Proceedings of the 22nd Annual Conference of the European Association for Machine Translation",
    month = nov,
    year = "2020",
    address = "Lisboa, Portugal",
    publisher = "European Association for Machine Translation",
    url = "https://aclanthology.org/2020.eamt-1.16",
    pages = "145--153",
    abstract = "Approaches to Quality Estimation (QE) of machine translation have shown promising results at predicting quality scores for translated sentences. However, QE models are often trained on noisy approximations of quality annotations derived from the proportion of post-edited words in translated sentences instead of direct human annotations of translation errors. The latter is a more reliable ground-truth but more expensive to obtain. In this paper, we present the first attempt to model the task of predicting the proportion of actual translation errors in a sentence while minimising the need for direct human annotation. For that purpose, we use transfer-learning to leverage large scale noisy annotations and small sets of high-fidelity human annotated translation errors to train QE models. Experiments on four language pairs and translations obtained by statistical and neural models show consistent gains over strong baselines.",
}
@inproceedings{kim-etal-2017-predictor,
    title = "Predictor-Estimator using Multilevel Task Learning with Stack Propagation for Neural Quality Estimation",
    author = "Kim, Hyun  and
      Lee, Jong-Hyeok  and
      Na, Seung-Hoon",
    editor = "Bojar, Ond{\v{r}}ej  and
      Buck, Christian  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Graham, Yvette  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      Koehn, Philipp  and
      Kreutzer, Julia",
    booktitle = "Proceedings of the Second Conference on Machine Translation",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-4763",
    doi = "10.18653/v1/W17-4763",
    pages = "562--568",
}
@inproceedings{ott2019fairseq,
  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  year = {2019},
}

@misc{le2016automatic,
      title={Automatic Quality Assessment for Speech Translation Using Joint ASR and MT Features}, 
      author={Ngoc-Tien Le and Benjamin Lecouteux and Laurent Besacier},
      year={2016},
      eprint={1609.06049},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{radford2022robust,
      title={Robust Speech Recognition via Large-Scale Weak Supervision}, 
      author={Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
      year={2022},
      eprint={2212.04356},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}
@misc{chowdhury2023multilingual,
      title={Multilingual Word Error Rate Estimation: e-WER3}, 
      author={Shammur Absar Chowdhury and Ahmed Ali},
      year={2023},
      eprint={2304.00649},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{ma2021deltalm,
      title={DeltaLM: Encoder-Decoder Pre-training for Language Generation and Translation by Augmenting Pretrained Multilingual Encoders}, 
      author={Shuming Ma and Li Dong and Shaohan Huang and Dongdong Zhang and Alexandre Muzio and Saksham Singhal and Hany Hassan Awadalla and Xia Song and Furu Wei},
      year={2021},
      eprint={2106.13736},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{sperber2024evaluating,
      title={Evaluating the IWSLT2023 Speech Translation Tasks: Human Annotations, Automatic Metrics, and Segmentation}, 
      author={Matthias Sperber and Ondřej Bojar and Barry Haddow and Dávid Javorský and Xutai Ma and Matteo Negri and Jan Niehues and Peter Polák and Elizabeth Salesky and Katsuhito Sudoh and Marco Turchi},
      year={2024},
      eprint={2406.03881},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.03881}, 
}
@INPROCEEDINGS{8683086,
  author={Vyas, Apoorv and Dighe, Pranay and Tong, Sibo and Bourlard, Hervé},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Analyzing Uncertainties in Speech Recognition Using Dropout}, 
  year={2019},
  volume={},
  number={},
  pages={6730-6734},
  keywords={Hidden Markov models;Uncertainty;Acoustics;Training;Decoding;Predictive models;Estimation;dropout uncertainty;WER estimation;word confidence;error localization},
  doi={10.1109/ICASSP.2019.8683086}}
@misc{seamless2023,
      title={SeamlessM4T: Massively Multilingual \& Multimodal Machine Translation}, 
      author={Seamless Communication and Loïc Barrault and Yu-An Chung and Mariano Cora Meglioli and David Dale and Ning Dong and Paul-Ambroise Duquenne and Hady Elsahar and Hongyu Gong and Kevin Heffernan and John Hoffman and Christopher Klaiber and Pengwei Li and Daniel Licht and Jean Maillard and Alice Rakotoarison and Kaushik Ram Sadagopan and Guillaume Wenzek and Ethan Ye and Bapi Akula and Peng-Jen Chen and Naji El Hachem and Brian Ellis and Gabriel Mejia Gonzalez and Justin Haaheim and Prangthip Hansanti and Russ Howes and Bernie Huang and Min-Jae Hwang and Hirofumi Inaguma and Somya Jain and Elahe Kalbassi and Amanda Kallet and Ilia Kulikov and Janice Lam and Daniel Li and Xutai Ma and Ruslan Mavlyutov and Benjamin Peloquin and Mohamed Ramadan and Abinesh Ramakrishnan and Anna Sun and Kevin Tran and Tuan Tran and Igor Tufanov and Vish Vogeti and Carleigh Wood and Yilin Yang and Bokai Yu and Pierre Andrews and Can Balioglu and Marta R. Costa-jussà and Onur Celebi and Maha Elbayad and Cynthia Gao and Francisco Guzmán and Justine Kao and Ann Lee and Alexandre Mourachko and Juan Pino and Sravya Popuri and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Paden Tomasello and Changhan Wang and Jeff Wang and Skyler Wang},
      year={2023},
      eprint={2308.11596},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.11596}, 
}
@article{2020SciPy-NMeth,
author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
      Haberland, Matt and Reddy, Tyler and Cournapeau, David and
      Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
      Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
      Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
      Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
      Kern, Robert and Larson, Eric and Carey, C J and
      Polat, Ilhan and Feng, Yu and Moore, Eric W. and
      {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
      Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
      Harris, Charles R. and Archibald, Anne M. and
      Ribeiro, Antonio H. and Pedregosa, Fabian and
      {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
      Computing in Python}},
journal = {Nature Methods},
year    = {2020},
volume  = {17},
pages   = {261--272},
adsurl  = {https://rdcu.be/b08Wh},
doi = {10.1038/s41592-019-0686-2},
}
@inproceedings{woodard1982,
author = {Woodard, J.P. and Nelson, J.T.},
year = {1982},
journal = {Workshop on standardisation for speech I/O technology; Naval Air Development Center; Warminster; PA},
title = {An information theoretic measure of speech recognition performance}
}

@inproceedings{morris2004,
author = {Morris, Andrew and Maier, Viktoria and Green, Phil},
year = {2004},
month = {01},
pages = {},
title = {From WER and RIL to MER and WIL: improved evaluation measures for connected speech recognition.}
}
@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{chi2021infoxlminformationtheoreticframeworkcrosslingual,
      title={InfoXLM: An Information-Theoretic Framework for Cross-Lingual Language Model Pre-Training}, 
      author={Zewen Chi and Li Dong and Furu Wei and Nan Yang and Saksham Singhal and Wenhui Wang and Xia Song and Xian-Ling Mao and Heyan Huang and Ming Zhou},
      year={2021},
      eprint={2007.07834},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2007.07834}, 
}
@misc{chung2021w2vbertcombiningcontrastivelearning,
      title={W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training}, 
      author={Yu-An Chung and Yu Zhang and Wei Han and Chung-Cheng Chiu and James Qin and Ruoming Pang and Yonghui Wu},
      year={2021},
      eprint={2108.06209},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2108.06209}, 
}
@misc{nllbteam2022languageleftbehindscaling,
      title={No Language Left Behind: Scaling Human-Centered Machine Translation}, 
      author={NLLB Team and Marta R. Costa-jussà and James Cross and Onur Çelebi and Maha Elbayad and Kenneth Heafield and Kevin Heffernan and Elahe Kalbassi and Janice Lam and Daniel Licht and Jean Maillard and Anna Sun and Skyler Wang and Guillaume Wenzek and Al Youngblood and Bapi Akula and Loic Barrault and Gabriel Mejia Gonzalez and Prangthip Hansanti and John Hoffman and Semarley Jarrett and Kaushik Ram Sadagopan and Dirk Rowe and Shannon Spruit and Chau Tran and Pierre Andrews and Necip Fazil Ayan and Shruti Bhosale and Sergey Edunov and Angela Fan and Cynthia Gao and Vedanuj Goswami and Francisco Guzmán and Philipp Koehn and Alexandre Mourachko and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Jeff Wang},
      year={2022},
      eprint={2207.04672},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2207.04672}, 
}
@misc{ott2019fairseqfastextensibletoolkit,
      title={fairseq: A Fast, Extensible Toolkit for Sequence Modeling}, 
      author={Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
      year={2019},
      eprint={1904.01038},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.01038}, 
}
@misc{guzmán2019floresevaluationdatasetslowresource,
      title={The FLoRes Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala-English}, 
      author={Francisco Guzmán and Peng-Jen Chen and Myle Ott and Juan Pino and Guillaume Lample and Philipp Koehn and Vishrav Chaudhary and Marc'Aurelio Ranzato},
      year={2019},
      eprint={1902.01382},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1902.01382}, 
}
@misc{gal2016dropoutbayesianapproximationrepresenting,
      title={Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning}, 
      author={Yarin Gal and Zoubin Ghahramani},
      year={2016},
      eprint={1506.02142},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1506.02142}, 
}
@inproceedings{banerjee-lavie-2005-meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    editor = "Goldstein, Jade  and
      Lavie, Alon  and
      Lin, Chin-Yew  and
      Voss, Clare",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W05-0909",
    pages = "65--72",
}
@inproceedings{sennrich-etal-2016-neural,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    editor = "Erk, Katrin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725",
}
@inproceedings{kudo-richardson-2018-sentencepiece,
    title = "{S}entence{P}iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing",
    author = "Kudo, Taku  and
      Richardson, John",
    editor = "Blanco, Eduardo  and
      Lu, Wei",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-2012",
    doi = "10.18653/v1/D18-2012",
    pages = "66--71",
    abstract = "This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at \url{https://github.com/google/sentencepiece}.",
}
@misc{dinh2023perturbationbasedqeexplainableunsupervised,
      title={Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation}, 
      author={Tu Anh Dinh and Jan Niehues},
      year={2023},
      eprint={2305.07457},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.07457}, 
}
@inproceedings{wang-etal-2018-alibaba,
    title = "{A}libaba Submission for {WMT}18 Quality Estimation Task",
    author = "Wang, Jiayi  and
      Fan, Kai  and
      Li, Bo  and
      Zhou, Fengming  and
      Chen, Boxing  and
      Shi, Yangbin  and
      Si, Luo",
    editor = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Fishel, Mark  and
      Graham, Yvette  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      Koehn, Philipp  and
      Monz, Christof  and
      Negri, Matteo  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Neves, Mariana  and
      Post, Matt  and
      Specia, Lucia  and
      Turchi, Marco  and
      Verspoor, Karin",
    booktitle = "Proceedings of the Third Conference on Machine Translation: Shared Task Papers",
    month = oct,
    year = "2018",
    address = "Belgium, Brussels",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-6465",
    doi = "10.18653/v1/W18-6465",
    pages = "809--815",
    abstract = "The goal of WMT 2018 Shared Task on Translation Quality Estimation is to investigate automatic methods for estimating the quality of machine translation results without reference translations. This paper presents the QE Brain system, which proposes the neural Bilingual Expert model as a feature extractor based on conditional target language model with a bidirectional transformer and then processes the semantic representations of source and the translation output with a Bi-LSTM predictive model for automatic quality estimation. The system has been applied to the sentence-level scoring and ranking tasks as well as the word-level tasks for finding errors for each word in translations. An extensive set of experimental results have shown that our system outperformed the best results in WMT 2017 Quality Estimation tasks and obtained top results in WMT 2018.",
}
